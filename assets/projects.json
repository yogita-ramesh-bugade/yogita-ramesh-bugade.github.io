{\rtf1\ansi\ansicpg1252\cocoartf2867
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 [\
  \{\
    "title": "Secure AI/ML Model Serving API",\
    "category": "AI Security",\
    "stack": "FastAPI \'95 Python \'95 JWT \'95 Redis \'95 Docker \'95 Trivy \'95 OPA",\
    "description": "Production-style model API with layered defenses against AI misuse patterns and strong auditability.",\
    "tags": ["Prompt Injection Defense", "JWT Auth", "Rate Limiting", "Audit Logging", "Policy-as-Code", "OWASP AI Top 10"],\
    "problem": "AI endpoints are high-value targets: attackers can abuse prompts, exfiltrate data, and overwhelm services.",\
    "approach": "Built a secure API gateway + model endpoint patterns: authentication, scoped authorization, input constraints, policy checks, and telemetry.",\
    "controls": [\
      "JWT authentication with least-privilege scopes",\
      "Rate limiting to reduce abuse and brute forcing",\
      "Policy-as-code checks before sensitive actions (OPA-style)",\
      "Audit logs with request identifiers for incident response",\
      "Container scanning with Trivy + secure defaults"\
    ],\
    "impact": "Demonstrates secure design patterns for AI APIs used in enterprises: accountability, control enforcement, and operational hardening.",\
    "repo": "https://github.com/YOUR_GITHUB/YOUR_SECURE_AI_API_REPO",\
    "demo": "#"\
  \},\
  \{\
    "title": "SOAR / EDR Automation: LimaCharlie + Tines",\
    "category": "Security Automation",\
    "stack": "SOAR Playbooks \'95 EDR Telemetry \'95 Incident Response",\
    "description": "Automated workflows that reduce repetitive SOC work while keeping human-in-the-loop safety and auditability.",\
    "tags": ["SOAR", "EDR", "Incident Response", "Playbooks", "Automation"],\
    "problem": "SOC teams waste time on repetitive triage and enrichment, and playbooks often become shelfware without structure.",\
    "approach": "Designed playbooks that are measurable: detection \uc0\u8594  enrichment \u8594  decision points \u8594  containment actions with logging.",\
    "controls": [\
      "Guardrails to prevent unsafe automation (approval steps)",\
      "Audit trail for each action in the workflow",\
      "Standardized enrichment for consistent triage",\
      "Containment steps with least privilege assumptions"\
    ],\
    "impact": "Shows you can engineer automation that is safe, maintainable, and operationally useful in real SOCs.",\
    "repo": "https://github.com/YOUR_GITHUB/YOUR_SOAR_REPO",\
    "demo": "#"\
  \},\
  \{\
    "title": "Threat Modeling Library for AI Systems",\
    "category": "Security Architecture",\
    "stack": "STRIDE \'95 OWASP AI Top 10 \'95 Markdown",\
    "description": "Reusable templates for threat modeling AI APIs, agent workflows, and RAG systems\'97mapped to controls.",\
    "tags": ["Threat Modeling", "STRIDE", "OWASP AI Top 10", "Secure Design"],\
    "problem": "Teams deploy AI features quickly but rarely document threats, assumptions, or mitigations for audits and security reviews.",\
    "approach": "Created repeatable templates + checklists to capture dataflows, trust boundaries, threats, and recommended controls.",\
    "controls": [\
      "Data classification and leakage controls",\
      "Authentication/authorization and tool access constraints",\
      "Logging, monitoring, and abuse prevention",\
      "Change control and policy mapping for compliance"\
    ],\
    "impact": "Demonstrates security architecture thinking and the ability to communicate risk clearly to stakeholders.",\
    "repo": "https://github.com/YOUR_GITHUB/YOUR_THREAT_MODEL_REPO",\
    "demo": "#"\
  \},\
  \{\
    "title": "IAM Patterns for Agentic Systems",\
    "category": "IAM / Authorization",\
    "stack": "Non-human identities \'95 On-behalf-of \'95 Least privilege",\
    "description": "Reference patterns that treat AI agents as first-class identities with lifecycle, revocation, and auditability.",\
    "tags": ["IAM", "Authorization", "Agents", "Least Privilege", "Auditability"],\
    "problem": "Agent workflows blur human vs agent actions, increasing risk of privilege escalation and weak accountability.",\
    "approach": "Designed authorization patterns: delegated on-behalf-of, scoped tokens, lifecycle controls, and revocation strategies.",\
    "controls": [\
      "Distinct identities for humans vs agents",\
      "Delegated authorization (on-behalf-of) patterns",\
      "Strict scope-limiting and rotation",\
      "Revocation and session invalidation approach"\
    ],\
    "impact": "Shows forward-looking IAM design for AI automation and compliance-heavy organizations.",\
    "repo": "https://github.com/YOUR_GITHUB/YOUR_IAM_AGENT_REPO",\
    "demo": "#"\
  \}\
]\
}